{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Variables](https://www.tensorflow.org/programmers_guide/variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ```tf.Variable``` \n",
    "- represents a tensor whose value can be changed by running ops on it. \n",
    "- unlike ```tf.Tensor``` objects, a ```tf.Variable``` exists outside the context of a single session.run call. Multiple workers can see the same values for a ```tf.Variable```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a variable\n",
    "The best way to create a variable is to call the ```tf.get_variable``` function. \n",
    "- requires you to specify the variable's name. \n",
    "- allows you to reuse a previously created variable of the same name, making it easy to define models which reuse layers.\n",
    "\n",
    "By default, have the dtype ```tf.float32``` and its initial value will be randomized via ```tf.glorot_uniform_initializer```.\n",
    "```python\n",
    "my_variable = tf.get_variable(\"my_variable\", [1, 2, 3]) # (name, shape)\n",
    "```\n",
    "Optionally specify the ```dtype``` and initializer to ```tf.get_variable```.\n",
    "```python\n",
    "my_int_variable = tf.get_variable(\"my_int_variable\", [1, 2, 3], dtype=tf.int32,\n",
    "  initializer=tf.zeros_initializer)\n",
    "```\n",
    "To have the value of a ```tf.Tensor```.\n",
    "```python\n",
    "other_variable = tf.get_variable(\"other_variable\", dtype=tf.int32, initializer=tf.constant([23, 42]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable collections\n",
    "Tensorflow provides **collections** to have a single way to access all of tensors or other objects, such as ```tf.Variable``` instances.\n",
    "\n",
    "By default every tf.Variable gets placed in the following two collections: \n",
    "- ```tf.GraphKeys.GLOBAL_VARIABLES```: variables that can be shared across multiple devices. \n",
    "- ```tf.GraphKeys.TRAINABLE_VARIABLES```: variables for which TensorFlow will calculate gradients.\n",
    "\n",
    "If you don't want a variable to be trainable, \n",
    "- add it to the ```tf.GraphKeys.LOCAL_VARIABLES``` collection instead. For example,\n",
    "```python\n",
    "my_local = tf.get_variable(\"my_local\", shape=(), collections=[tf.GraphKeys.LOCAL_VARIABLES])\n",
    "```\n",
    "- Alternatively, you can specify ```trainable=False``` as an argument to ```tf.get_variable```.\n",
    "```python\n",
    "my_non_trainable = tf.get_variable(\"my_non_trainable\", shape=(), trainable=False)\n",
    "```\n",
    "\n",
    "You can also use your own collections. Any string is a valid collection name, and there is no need to explicitly create a collection.\n",
    "```python\n",
    "tf.add_to_collection(\"my_collection_name\", my_local)\n",
    "```\n",
    "And to retrieve a list of all the variables (or other objects) you've placed in a collection you can use:\n",
    "```python\n",
    "tf.get_collection(\"my_collection_name\")\n",
    "```\n",
    "### Device placement\n",
    "come later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variables\n",
    "Variables must be initialized. \n",
    "- Most high-level frameworks such as ```tf.contrib.slim```, ```tf.estimator.Estimator``` and Keras automatically initialize variables for you before training a model.\n",
    "- Explicit initialization is otherwise useful. It\n",
    "  - avoid potentially expensive initializers \n",
    "  - allow determinism when randomly-initialized variables are shared in a distributed setting\n",
    "- ```tf.global_variables_initializer()``` initializes all trainable variables. This function initializes all variables in the ```tf.GraphKeys.GLOBAL_VARIABLES``` collection.\n",
    "```python\n",
    "session.run(tf.global_variables_initializer())\n",
    "# Now all variables are initialized.\n",
    "```\n",
    "- Initialize variables explicitly\n",
    "```python\n",
    "session.run(my_variable.initializer)\n",
    "```\n",
    "- Check which variables have not been initialized\n",
    "```python\n",
    "print(session.run(tf.report_uninitialized_variables()))\n",
    "```\n",
    "- Use ```variable.initialized_value()```, any time the value of a variable in a context in which not all variables are initialized (say, if you use a variable's value while initializing another variable)\n",
    "```python\n",
    "v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "w = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using variables\n",
    "To use the value of a ```tf.Variable``` in a TensorFlow graph, simply treat it like a normal ```tf.Tensor```:\n",
    "```python\n",
    "v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "w = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n",
    "           # Any time a variable is used in an expression it gets automatically\n",
    "           # converted to a tf.Tensor representing its value.\n",
    "```\n",
    "To assign a value to a variable, use the methods ```assign```, ```assign_add```, and friends in the ```tf.Variable``` class.\n",
    "```python\n",
    "v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "assignment = v.assign_add(1)\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(assignment)  # or assignment.op.run(), or assignment.eval()\n",
    "```\n",
    "\n",
    "To force a re-read of the value of a variable after something has happened, use ```tf.Variable.read_value```.\n",
    "```python\n",
    "v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "assignment = v.assign_add(1)\n",
    "with tf.control_dependencies([assignment]):\n",
    "  w = v.read_value()  # w is guaranteed to reflect v's value after the\n",
    "                      # assign_add operation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing variables\n",
    "TensorFlow supports two ways of sharing variables.\n",
    "- Explicitly passing ```tf.Variable``` objects around.\n",
    "- Implicitly wrapping ```tf.Variable``` objects within ```tf.variable_scope``` objects.\n",
    "\n",
    "Variable scopes allow you to control variable reuse when calling functions which implicitly create and use variables.\n",
    "\n",
    "Suppose, we want to create a convolutional/relu layer\n",
    "```python\n",
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape, initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "```\n",
    "If we want many such convolutional layers, calling this function repeatedly wouldn't work.\n",
    "```python\n",
    "input1 = tf.random_normal([1,10,10,32])\n",
    "input2 = tf.random_normal([1,20,20,32])\n",
    "x = conv_relu(input1, kernel_shape=[5, 5, 32, 32], bias_shape=[32])\n",
    "x = conv_relu(x, kernel_shape=[5, 5, 32, 32], bias_shape = [32])  # This fails.\n",
    "```\n",
    "creating new \"weights\" and \"biases\" variables or reuse the existing ones is unclear. \n",
    "\n",
    "Calling ```conv_relu``` in scopes solves this ambiguity.\n",
    "- create new variables\n",
    "```python\n",
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5, 5, 32, 32], [32])\n",
    "```\n",
    "\n",
    "- want the variables to be shared\n",
    "  - use ```reuse=True```\n",
    "  ```python\n",
    "  with tf.variable_scope(\"model\"):\n",
    "      output1 = my_image_filter(input1)\n",
    "  with tf.variable_scope(\"model\", reuse=True):\n",
    "      output2 = my_image_filter(input2)\n",
    "  # or\n",
    "  with tf.variable_scope(\"model\") as scope:\n",
    "      output1 = my_image_filter(input1)\n",
    "  with tf.variable_scope(scope, reuse=True): # initialize a variable scope based on another one\n",
    "      output3 = my_image_filter(input2)\n",
    "  ```\n",
    "  - call ```scope.reuse.variables()``` to trigger a reuse\n",
    "  ```python\n",
    "  with tf.variable_scope(\"model\") as scope:\n",
    "      output1 = my_image_filter(input1)\n",
    "      scope.reuse_variables()\n",
    "      output2 = my_image_filter(input2)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[2, 2, 2, 2, 2]\n",
      "[2 2 2 2 2]\n",
      "[ 1.  5.  9. 13. 17.]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "# placeholder for batch pairs of observations and actions\n",
    "tf_data = tf.placeholder(shape = None, name = \"data\", dtype = tf.float32)\n",
    "tf_lens = tf.placeholder(shape = [None], name = \"lens\", dtype = tf.int32)\n",
    "\n",
    "# tf_lens = tf.constant(5)\n",
    "\n",
    "# tf_first = tf.split(tf_data, tf_lens)\n",
    "\n",
    "#v = tf.get_variable(\"v\", shape=(2,), initializer=tf.constant_initializer([2.0, 3.0]))\n",
    "#w = tf.get_variable(\"w\", shape=(), initializer=tf.constant_initializer(1.0))\n",
    "# tf.slice(v, [0], [1]) = w\n",
    "\n",
    "#y = tf.slice(v, [0], [1])[0]\n",
    "#l1 = [y+1, w]\n",
    "#l2 = [y+w, y*w]\n",
    "\n",
    "# l3 = [l1, l2]\n",
    "\n",
    "#z = tf.nn.softmax(l1)\n",
    "\n",
    "#assignment = v.assign_add([2.0, 2.0])\n",
    "\n",
    "a = np.arange(10)\n",
    "lens = [2,2,2,2,2]\n",
    "\n",
    "print(a)\n",
    "print(lens)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.__enter__() # equivalent to `with sess:`\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    # print([y.eval(), w.eval()])\n",
    "    # print(z.eval())\n",
    "feed_dict = {tf_lens:lens}\n",
    "    # feed_dict = {tf_data:a}\n",
    "y = sess.run([tf_lens], feed_dict = feed_dict)\n",
    "    #first = sess.run(tf_first, feed_dict = feed_dict)\n",
    "    #print(np.array(first))\n",
    "    # print(tf_data_group.eval())\n",
    "    \n",
    "print(y[0])\n",
    "    \n",
    "tf_first = tf.split(tf_data, y[0])\n",
    "#sums = []\n",
    "#for i in range(len(tf_first)):\n",
    "#    tf_sum = tf.reduce_sum(tf_first[i], 0)\n",
    "#    sums.append(tf_sum)\n",
    "\n",
    "#soft_sums = tf.nn.softmax(sums)\n",
    "z = sess.run(tf.reduce_sum(tf_first, 1), feed_dict = {tf_data:a})\n",
    "print(z)\n",
    "\n",
    "x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "g = tf.reduce_sum(x)\n",
    "print(sess.run(g))\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
